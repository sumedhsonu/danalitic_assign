{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv(r'C:\\Users\\Acer\\Downloads\\data files and problem statement\\Sales (1).tsv',sep=\"\\t\",header=0)\n",
    "complaints = pd.read_csv(r'C:\\Users\\Acer\\Downloads\\data files and problem statement\\Complaints (1).tsv',sep=\"\\t\",header=0)\n",
    "Production_logs=pd.read_csv(r'C:\\Users\\Acer\\Downloads\\data files and problem statement\\Production_logs (1).tsv',sep=\"\\t\",header=0)\n",
    "#reading data as dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales.iloc[0:,0:4]\n",
    "Production_logs = Production_logs.iloc[0:,0:4]\n",
    "#taking only important columns into consideration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# solution for report1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_Frame = pd.merge(sales,complaints, on = 'Invoice_Id',how='inner')\n",
    "#merging columns sales and complaints based on invoice id as it only similar column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_Frame1 = pd.merge(merged_Frame,Production_logs, on = 'Batch_Id',how='inner')\n",
    "#merging columns previous frame and Production_logs based on Batch_Id as it only similar column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=merged_Frame1['Items_Summary'].map(eval)\n",
    "df1= df1.apply(pd.Series)\n",
    "df1=df1.fillna(0)\n",
    "df1=df1.rename(columns={\"rock\": \"rock_Items_Summary\", \"scissor\": \"scissor_Items_Summary\",\"paper\": \"paper_Items_Summary\"})\n",
    "#using map to convert string to dictionary\n",
    "#seperating dictionaries\n",
    "#filling the nan with zeroes\n",
    "#changing name of the for easy understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=merged_Frame1['Items_produced'].map(eval)\n",
    "df2= df2.apply(pd.Series)\n",
    "df2=df2.fillna(0)\n",
    "df2=df2.rename(columns={\"rock\": \"rock_Items_produced\", \"scissor\": \"scissor_Items_produced\",\"paper\": \"paper_Items_produced\"})\n",
    "#using map to convert string to dictionary\n",
    "#seperating dictionaries\n",
    "#filling the nan with zeroes\n",
    "#changing name of the for easy understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=merged_Frame1['Items_discarded'].map(eval)\n",
    "df3= df3.apply(pd.Series)\n",
    "df3=df3.fillna(0)\n",
    "df3=df3.rename(columns={\"rock\": \"rock_Items_discarded\", \"scissor\": \"scissor_Items_discarded\",\"paper\": \"paper_Items_discarded\"})\n",
    "#using map to convert string to dictionary\n",
    "#seperating dictionaries\n",
    "#filling the nan with zeroes\n",
    "#changing name of the for easy understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df.sort_values(by='Production_Unit_Id')\n",
    "#sorting values based on production id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main=df4.drop(['Items_Summary', 'Items_produced','Items_discarded'], axis=1)\n",
    "#dropping unrequired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_1=df_main.iloc[0:,3:]\n",
    "df_main_2=df_main.iloc[0:,3]\n",
    "df_main_3=df_main.iloc[0:,1]\n",
    "#taking columns which are required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_2=pd.get_dummies(df_main_2)\n",
    "#converting complaints columns i.e categorical into numerical for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_prob1 =pd.concat([df_main_3,df_main_2,df_main_1],join='outer',axis=1)\n",
    "#merging the above frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_prob1=df_main_prob1.drop(['Defective_Item'],axis=1)\n",
    "#removing the column defective item as it is already converted to numerical in previous steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_prob1[\"final_paper_Items_Summary\"] = df_main_prob1[\"paper\"] * df_main_prob1[\"paper_Items_Summary\"]\n",
    "df_main_prob1[\"final_rock_Items_Summary\"] = df_main_prob1[\"rock\"] * df_main_prob1[\"rock_Items_Summary\"]\n",
    "df_main_prob1[\"final_scissor_Items_Summary\"] = df_main_prob1[\"scissor\"] * df_main_prob1[\"scissor_Items_Summary\"]\n",
    "#the numerical column is multiplied by items summary to get the amount of items which are complained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_prob1=df_main_prob1.iloc[0:,4:]\n",
    "#taking the required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_prob1=df_main_prob1.iloc[0:,4:]\n",
    "#taking the required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_prob1=pd.concat([df_main['Production_Unit_Id'],df_main_prob1],join='outer',axis=1)\n",
    "#merging above frames as it does not have column names production id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_prob1[\"final_rock_Total_defective\"] = df_main_prob1[\"rock_Items_discarded\"] + df_main_prob1[\"final_rock_Items_Summary\"]\n",
    "df_main_prob1[\"final_scissor_Total_defective\"] = df_main_prob1[\"scissor_Items_discarded\"] + df_main_prob1[\"final_scissor_Items_Summary\"]\n",
    "df_main_prob1[\"final_paper_Total_defective\"] = df_main_prob1[\"paper_Items_discarded\"] + df_main_prob1[\"final_paper_Items_Summary\"]\n",
    "#total defective is nothing but number of items discarded plus the items which are complained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob1=df_main_prob1.iloc[0:,0:4] \n",
    "df_prob2=df_main_prob1.iloc[0:,10:]\n",
    "#taking required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob=pd.concat([df_prob1,df_prob2],join='outer',axis=1)\n",
    "#merging two frames to get features from both frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob=pd.concat([df_main['Batch_Id'],df_prob],join='outer',axis=1)\n",
    "#merging two frames to get features from both frames because it doesnt have column named batch id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob_1_prod=df_prob.iloc[0:,0:5]\n",
    "df_prob_1_def=df_prob.iloc[0:,5:]\n",
    "#taking required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob_1_def=pd.concat([df_prob['Production_Unit_Id'],df_prob_1_def],join='outer',axis=1)\n",
    "#merging two frames to get features from both frames because it doesnt have column named Production_Unit_Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob_1_prod_fin=df_prob_1_prod.drop_duplicates(subset=['Batch_Id'], keep='first')\n",
    "#removing the duplicate items using batch id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob_1_def_fin =df_prob_1_def.groupby('Production_Unit_Id').sum()     #total  defective for production id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob_1_prod_fin=df_prob_1_prod_fin.groupby('Production_Unit_Id').sum() #total  produced for production id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.merge(df_prob_1_prod_fin,df_prob_1_def_fin, on = 'Production_Unit_Id',how='inner')\n",
    "#merging two frames to get features from both frames because it doesnt have column named Production_Unit_Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"percentage_of_paper_defective\"] = df[\"final_paper_Total_defective\"] / df[\"paper_Items_produced\"] * 100\n",
    "df[\"percentage_of_rock_defective\"] = df[\"final_rock_Total_defective\"] / df[\"rock_Items_produced\"] * 100\n",
    "df[\"percentage_of_scissor_defective\"] = df[\"final_scissor_Total_defective\"] / df[\"scissor_Items_produced\"] * 100\n",
    "#percentage of defective is nothing but total defective divide by total produced which is multiplies by 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob1_sol=df.drop(['final_rock_Total_defective','final_scissor_Total_defective','final_paper_Total_defective','scissor_Items_produced','paper_Items_produced','rock_Items_produced'], axis = 1)\n",
    "#droping unrequired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob1_sol.to_csv(r'C:\\Users\\Acer\\Downloads\\report1.csv')\n",
    "#saving the data frame as csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# solution for report3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_prob3=df_main_prob1.iloc[0:,0:7]\n",
    "#taking required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_prob3=pd.concat([df_main['Batch_Id'],df_main_prob3],join='outer',axis=1)\n",
    "#merging two frames onn batch id to get common features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_prob3=df_main_prob3.drop_duplicates(subset=['Batch_Id'], keep='first')\n",
    "#removing duplicated i.e which is the repeated batch id rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_prob3=df_main_prob3.groupby('Production_Unit_Id').sum() \n",
    "#grouping the columns based on production id and summing up other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_prob3['total_items_produced']=df_main_prob3['scissor_Items_produced']+df_main_prob3['paper_Items_produced']+df_main_prob3['rock_Items_produced']\n",
    "df_main_prob3['total_items_discarded']=df_main_prob3['scissor_Items_discarded']+df_main_prob3['paper_Items_discarded']+df_main_prob3['rock_Items_discarded']\n",
    "#merging columns it between i.e rock+paper+scissor=total for both produced and the items dicarded after the quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_prob3=df_main_prob3.drop(['scissor_Items_produced','paper_Items_produced','rock_Items_produced','scissor_Items_discarded','paper_Items_discarded','rock_Items_discarded'],axis=1)\n",
    "#removing the unrequired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_prob3['%_detected_defects_by_QA']=df_main_prob3['total_items_discarded']/df_main_prob3['total_items_produced']*100\n",
    "#total percentage of defective is equal to total items dicarded during QC by total items produced multiplied by 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_prob3=df_main_prob3.drop(['total_items_produced','total_items_discarded'],axis=1)\n",
    "#dropping unrequired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_prob3.to_csv(r'C:\\Users\\Acer\\Downloads\\report3.csv')\n",
    "#saving the dataframe as csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# solution for report2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob_2=df_main.iloc[0:,0:8]\n",
    "#taking the required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob_2=df_prob_2.drop(['Invoice_Id','Batch_Id','Production_Unit_Id'],axis=1)\n",
    "#droping the columns which are in not use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob_2=df_prob_2.sort_values(by='Customer_Id')\n",
    "#sorting columns based on customer id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob_2=df_prob_2.rename(columns={\"rock_Items_Summary\": \"Rocks_bought\", \"scissor_Items_Summary\": \"Scissors_bought\",\"paper_Items_Summary\": \"Paper_Bought\"})\n",
    "#changing column names for easy understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df_prob_2.iloc[0:,1]\n",
    "#taking the required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.get_dummies(a)\n",
    "#converting defective item column to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob_2=pd.concat([a,df_prob_2],join='outer',axis=1)\n",
    "#combining two columns  after dummyfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob_2=df_prob_2.drop(['Defective_Item'],axis=1)\n",
    "#droping the columns which are in not use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob2_fin=df_prob_2.groupby('Customer_Id').sum()\n",
    "#grouping other columns based on customer id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob2_fin['Number_of_complaints']=df_prob2_fin['paper']+df_prob2_fin['rock']+df_prob2_fin['scissor']\n",
    "#number of total complaint is the sum of individual item complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob2_fin=df_prob2_fin.drop(['paper','rock','scissor'],axis=1)\n",
    "#droping the columns which are in not use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=df_prob2_fin.reset_index(level=0)\n",
    "#changing the index to use in further steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=b.iloc[0:,0]\n",
    "#taking index column separetaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=b.str.split(pat=('0'),expand=True)\n",
    "b=b.iloc[0:,0]\n",
    "#splitting index column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=b.str.split(pat=('1'),expand=True)\n",
    "b=b.iloc[0:,0]\n",
    "#splitting index column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=b.str.split(pat=('2'),expand=True)\n",
    "b=b.iloc[0:,0]\n",
    "#splitting index column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=b.str.split(pat=('3'),expand=True)\n",
    "b=b.iloc[0:,0]\n",
    "#splitting index column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=b.str.split(pat=('4'),expand=True)\n",
    "b=b.iloc[0:,0]\n",
    "#splitting index column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=b.str.split(pat=('5'),expand=True)\n",
    "b=b.iloc[0:,0]\n",
    "#splitting index column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=b.str.split(pat=('6'),expand=True)\n",
    "b=b.iloc[0:,0]\n",
    "#splitting index column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=b.str.split(pat=('7'),expand=True)\n",
    "b=b.iloc[0:,0]\n",
    "#splitting index column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=b.str.split(pat=('8'),expand=True)\n",
    "b=b.iloc[0:,0]\n",
    "#splitting index column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=b.str.split(pat=('9'),expand=True)\n",
    "b=b.iloc[0:,0]\n",
    "#splitting index column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=df_prob2_fin.reset_index(level=0)\n",
    "#resetting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob2_final=pd.concat([b,c],join='outer',axis=1)\n",
    "#joining two frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob2_final=df_prob2_final.drop(['Customer_Id'],axis=1)\n",
    "#dropping unrequired column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob2_final=df_prob2_final.groupby(0).sum()\n",
    "#grouping by column number 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob2_final=df_prob2_final.rename_axis('Customer_Group')\n",
    "#renaming column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_titles = [\"Number_of_complaints\",\"Rocks_bought\",\"Scissors_bought\",\"Paper_Bought\"]\n",
    "df_prob2_end=df_prob2_final.reindex(columns=columns_titles)\n",
    "#resetting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob2_end.to_csv(r'C:\\Users\\Acer\\Downloads\\report2.csv')\n",
    "#saving the frame as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
